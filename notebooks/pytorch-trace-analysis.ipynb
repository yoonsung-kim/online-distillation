{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080-batch-16-alexnet-trace.json\n",
      "1080-batch-16-resnet34-trace.json\n",
      "1080-batch-32-alexnet-trace.json\n",
      "1080-batch-32-resnet34-trace.json\n",
      "3090-batch-16-alexnet-trace.json\n",
      "3090-batch-16-resnet34-trace.json\n",
      "3090-batch-32-alexnet-trace.json\n",
      "3090-batch-32-resnet34-trace.json\n"
     ]
    }
   ],
   "source": [
    "gpu_lists = ['1080', '3090']\n",
    "batch_sizes = ['16', '32']\n",
    "models = ['alexnet', 'resnet34']\n",
    "\n",
    "trace_files = []\n",
    "for gpu in gpu_lists:\n",
    "    for batch in batch_sizes:\n",
    "        for model in models:\n",
    "            trace_files.append(f'{gpu}-batch-{batch}-{model}-trace.json')\n",
    "\n",
    "for trace in trace_files:\n",
    "    print(trace)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schemaVersion\n",
      "deviceProperties\n",
      "traceEvents\n",
      "Memcpy HtoD (Pageable -> Device)\n",
      "Memset (Device)\n",
      "cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)\n",
      "maxwell_scudnn_128x32_relu_large_nn_v1\n",
      "maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile418n_nt_v1\n",
      "maxwell_sgemm_128x64_nn\n",
      "sgemm_32x32x32_NT_vec\n",
      "void at::native::(anonymous namespace)::adaptive_average_pool<float>(float*, float*, int, int, int, int, long, long, long)\n",
      "void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)\n",
      "void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)\n",
      "void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)\n",
      "void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)\n",
      "void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)\n",
      "void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)\n",
      "void cudnn::winograd_nonfused::winogradForwardData9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)\n",
      "void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)\n",
      "void cudnn::winograd_nonfused::winogradForwardFilter9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)\n",
      "void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)\n",
      "void cudnn::winograd_nonfused::winogradForwardOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)\n"
     ]
    }
   ],
   "source": [
    "with open('./1080-batch-32-alexnet-trace.json') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "    for key in json_data.keys():\n",
    "        print(key)\n",
    "\n",
    "    events = json_data['traceEvents']\n",
    "\n",
    "    cuda_events = []\n",
    "    for event in events:\n",
    "        if 'stream' in str(event['tid']) and 'name' in event.keys() and 'dur' in event.keys():\n",
    "            cuda_events.append(event)\n",
    "\n",
    "    kernel_names = []\n",
    "    for event in cuda_events:\n",
    "        kernel_names.append(event['name'])\n",
    "\n",
    "    kernel_names = np.unique(kernel_names)\n",
    "    for name in kernel_names:\n",
    "        print(name)\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}